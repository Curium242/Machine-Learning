# -*- coding: utf-8 -*-
"""ImageClassification_Traffic Sign.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EULVM0onU08UpzxprqL2NOMPi-pbnebu
"""

from google.colab import files
files.upload()

!pip install -q kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# Commented out IPython magic to ensure Python compatibility.
!mkdir traffic_sign_dataset
# %cd traffic_sign_dataset

!kaggle datasets list -s gtsrb-german-traffic-sign

!kaggle datasets download meowmeowmeowmeowmeow/gtsrb-german-traffic-sign

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

!unzip traffic_sign_dataset/gtsrb-german-traffic-sign.zip -d traffic_sign_dataset
!rm traffic_sign_dataset/gtsrb-german-traffic-sign.zip
!rm -rf traffic_sign_dataset/Meta
!rm -rf traffic_sign_dataset/meta
!rm -rf traffic_sign_dataset/test
!rm -rf traffic_sign_dataset/train
!rm traffic_sign_dataset/Meta.csv

import os
import pandas as pd
import numpy as np
import random
from PIL import Image
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout,Conv2D,MaxPool2D

import matplotlib.pyplot as plt
from matplotlib.image import imread

dim1=[]
dim2=[]
for i in range(0,43):
  labels='traffic_sign_dataset/Train'+'/{0}'.format(i)
  image_path=os.listdir(labels)
  print("Image filenames in class", i, ":", image_path)
  for x in image_path:
    img=imread(labels+'/'+x)
    dim1.append(img.shape[0])
    dim2.append(img.shape[1])

print("Dimension 1 Mean : ",np.mean(dim1), " Dimension 2 Mean : ",np.mean(dim2))

imgs=[]
labelid=[]
for i in range(43):
  labels='traffic_sign_dataset/Train' + '/{0}'.format(i)
  image_path=os.listdir(labels)
  for x in image_path:
    img=Image.open(labels+'/'+x)
    img=img.resize((50,50))
    img=np.array(img)
    imgs.append(img)
    labelid.append(i)

imgs=np.array(imgs)

imgs=imgs/255
imgs.shape

labelid=np.array(labelid)
labelid.shape

x_train, x_val, y_train, y_val = train_test_split(imgs, labelid , test_size = 0.2, random_state = 42)

y_train_cat = to_categorical(y_train)
y_val_cat = to_categorical(y_val)

from tensorflow.keras.layers import BatchNormalization

model = Sequential()

model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=x_train.shape[1:], activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Dense(43, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

model.fit(x_train, y_train, epochs = 15, batch_size = 128, validation_data = (x_val, y_val), verbose = 2)

evaluation = pd.DataFrame(model.history.history)
evaluation[['accuracy', 'val_accuracy']].plot()
evaluation[['loss', 'val_loss']].plot()

test_path = 'traffic_sign_dataset/Test'
!rm traffic_sign_dataset/Test/GT-final_test.csv

from PIL import Image
def scaling(test_images,test_path):
  images=[]
  image_path=test_images

  for x in image_path:
    img=Image.open(test_path+'/'+x)
    img=img.resize((50,50))
    img=np.array(img)
    images.append(img)
  images=np.array(images)
  images=images/255
  return images

test_images = scaling(sorted(os.listdir(test_path)),test_path)

test = pd.read_csv('traffic_sign_dataset/Test.csv')
y_test = test['ClassId'].values
y_test

all_lables = ['Speed limit (20km/h)','Speed limit (30km/h)','Speed limit (50km/h)','Speed limit (60km/h)',
              'Speed limit (70km/h)','Speed limit (80km/h)','End of speed limit (80km/h)','Speed limit (100km/h)',
              'Speed limit (120km/h)','No passing','No passing for vechiles over 3.5 metric tons',
              'Right-of-way at the next intersection','Priority road','Yield','Stop','No vechiles',
              'Vechiles over 3.5 metric tons prohibited','No entry','General caution','Dangerous curve to the left',
              'Dangerous curve to the right','Double curve','Bumpy road','Slippery road','Road narrows on the right',
              'Road work','Traffic signals','Pedestrians','Children crossing','Bicycles crossing','Beware of ice/snow',
              'Wild animals crossing','End of all speed and passing limits','Turn right ahead','Turn left ahead',
              'Ahead only','Go straight or right','Go straight or left','Keep right','Keep left','Roundabout mandatory',
              'End of no passing','End of no passing by vechiles over 3.5 metric']

import numpy as np
y_pred_probabilities = model.predict(test_images)
y_pred = np.argmax(y_pred_probabilities, axis=1);
y_pred

img = Image.open(test_path + '/00002.png')
print("Original label : ",all_lables[y_test[2]])
print("Predicted label : ",all_lables[y_pred[2]])
img

