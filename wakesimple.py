# -*- coding: utf-8 -*-
"""wakesimple.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PeRWjvelnC7ZGZIbhikDPQuMFJ5PcnU6
"""



from google.colab import drive
drive.mount('/content/drive')

!pip install ultralytics tqdm xmltodict --quiet

import os
import random
import xml.etree.ElementTree as ET
import xmltodict
import shutil
from tqdm import tqdm
import cv2
import numpy as np
from ultralytics import YOLO

IMAGE_DIR = "/content/drive/MyDrive/shipwake/SWIM_Dataset_1.0.0/JPEGImages"
ANNOTATION_DIR = "/content/drive/MyDrive/shipwake/SWIM_Dataset_1.0.0/Annotations"
NEGATIVE_DIR = "/content/drive/MyDrive/shipwake/SWIM_Dataset_1.0.0/Negative"
LANDMARK_DIR = "/content/drive/MyDrive/shipwake/SWIM_Dataset_1.0.0/Landmarks"  

WORK_DIR = "/content/shipwake_phase1"  
os.makedirs(WORK_DIR, exist_ok=True)

TRAIN_IMAGES_DIR = os.path.join(WORK_DIR, "images", "train")
VAL_IMAGES_DIR = os.path.join(WORK_DIR, "images", "val")
os.makedirs(TRAIN_IMAGES_DIR, exist_ok=True)
os.makedirs(VAL_IMAGES_DIR, exist_ok=True)

TRAIN_LABELS_DIR = os.path.join(WORK_DIR, "labels", "train")
VAL_LABELS_DIR = os.path.join(WORK_DIR, "labels", "val")
os.makedirs(TRAIN_LABELS_DIR, exist_ok=True)
os.makedirs(VAL_LABELS_DIR, exist_ok=True)

import math

def oriented_box_to_axis_aligned(cx, cy, w, h, angle):
    """
    Convert (cx, cy, w, h, angle) in image coords
    to an axis-aligned bounding box [xmin, ymin, xmax, ymax].
    """
    # Four corners of the OBB in (x, y)
    # angle is in radians. The dataset angle might be in rad, but check if it’s degrees in your data.
    # The example uses (−π/2, π/2) range, so it should be radians.
    # If your data was in degrees, you'd do `angle_radians = math.radians(angle)`.
    c = math.cos(angle)
    s = math.sin(angle)
    # half dims
    w2 = w / 2.0
    h2 = h / 2.0

    # corner offsets
    corners = [
        (+w2*c - h2*s, +w2*s + h2*c),
        (-w2*c - h2*s, -w2*s + h2*c),
        (-w2*c + h2*s, -w2*s - h2*c),
        (+w2*c + h2*s, +w2*s - h2*c),
    ]

    # Shift corners by center (cx, cy)
    corners = [(cx + x, cy + y) for (x, y) in corners]

    xs = [pt[0] for pt in corners]
    ys = [pt[1] for pt in corners]
    xmin, xmax = min(xs), max(xs)
    ymin, ymax = min(ys), max(ys)
    return xmin, ymin, xmax, ymax

# 3.1) Gather all positive annotation files
all_ann_paths = sorted([os.path.join(ANNOTATION_DIR, f)
                        for f in os.listdir(ANNOTATION_DIR)
                        if f.lower().endswith('.xml')])

# 3.2) OPTIONAL: gather negative images (where there's no wake)
all_negative_paths = sorted([os.path.join(NEGATIVE_DIR, f)
                             for f in os.listdir(NEGATIVE_DIR)
                             if f.lower().endswith('.jpg') or f.lower().endswith('.png')])

# 3.3) Randomly sample ~500 positives (or fewer if you want)
random.shuffle(all_ann_paths)
subset_ann_paths = all_ann_paths[:5000]

# 3.4) Let's do a train/val split: 80% train, 20% val
train_cutoff = int(0.99 * len(subset_ann_paths))
train_ann_paths = subset_ann_paths[:train_cutoff]
val_ann_paths = subset_ann_paths[train_cutoff:]

print("Train annotation files:", len(train_ann_paths))
print("Val annotation files:", len(val_ann_paths))

def parse_swim_xml(xml_path):
    """
    Returns: a list of (xmin, ymin, xmax, ymax) in pixel coords
             that correspond to 'wake' objects.
    Also returns the image filename + size.
    """
    with open(xml_path, 'r') as f:
        data = xmltodict.parse(f.read())

    ann = data['annotation']

    filename = ann['filename'] + "." + ann['format']
    width = int(ann['size']['width'])
    height = int(ann['size']['height'])

    objects = ann.get('object', [])
    # If there's only 1 object, 'object' might not be a list but a dict
    if isinstance(objects, dict):
        objects = [objects]

    bboxes = []
    for obj in objects:
        name = obj['name']
        if name.lower() != 'wake':
            # skip if not 'wake'
            continue

        # Possible: "robndbox" or "bndbox" or "pointtheta"
        obj_type = obj['type']
        if obj_type == 'robndbox':
            rbox = obj['robndbox']
            cx = float(rbox['cx'])
            cy = float(rbox['cy'])
            w = float(rbox['w'])
            h = float(rbox['h'])
            angle = float(rbox['angle'])

            xmin, ymin, xmax, ymax = oriented_box_to_axis_aligned(cx, cy, w, h, angle)
            # Clip to image boundaries just in case
            xmin = max(0, min(xmin, width-1))
            xmax = max(0, min(xmax, width-1))
            ymin = max(0, min(ymin, height-1))
            ymax = max(0, min(ymax, height-1))

            if xmax <= xmin or ymax <= ymin:
                continue

            bboxes.append((xmin, ymin, xmax, ymax))
        elif obj_type == 'bndbox':
            # If you had axis-aligned bndbox
            bnd = obj['bndbox']
            xmin = float(bnd['xmin'])
            ymin = float(bnd['ymin'])
            xmax = float(bnd['xmax'])
            ymax = float(bnd['ymax'])
            # Similarly, clip
            xmin = max(0, min(xmin, width-1))
            xmax = max(0, min(xmax, width-1))
            ymin = max(0, min(ymin, height-1))
            ymax = max(0, min(ymax, height-1))
            if xmax <= xmin or ymax <= ymin:
                continue
            bboxes.append((xmin, ymin, xmax, ymax))
        # If it's "pointtheta", skip for bounding box extraction
        # (We'll handle angles later)

    return filename, width, height, bboxes

def write_yolo_label(bboxes, img_w, img_h, label_path):
    """
    Write bboxes to label_path in YOLO <class> <xc> <yc> <w> <h> format (normalized).
    class = 0 (wake)
    """
    lines = []
    for (xmin, ymin, xmax, ymax) in bboxes:
        xc = (xmin + xmax) / 2.0
        yc = (ymin + ymax) / 2.0
        bw = xmax - xmin
        bh = ymax - ymin

        # normalize
        xc_norm = xc / img_w
        yc_norm = yc / img_h
        bw_norm = bw / img_w
        bh_norm = bh / img_h

        lines.append(f"0 {xc_norm:.6f} {yc_norm:.6f} {bw_norm:.6f} {bh_norm:.6f}")

    with open(label_path, 'w') as f:
        f.write("\n".join(lines))

def process_annotation_files(ann_paths, out_img_dir, out_label_dir):
    cnt = 0
    for xml_file in tqdm(ann_paths, desc="Processing annotations"):
        filename, w, h, bboxes = parse_swim_xml(xml_file)

        # Copy or link the corresponding image into out_img_dir
        src_img = os.path.join(IMAGE_DIR, filename)
        if not os.path.exists(src_img):
            # Some images might be missing or in a different folder
            # Potentially skip or handle differently
            continue

        # Destination
        dst_img = os.path.join(out_img_dir, filename)
        shutil.copyfile(src_img, dst_img)

        # YOLO label path (same name, .txt extension)
        base_name = os.path.splitext(filename)[0]
        label_path = os.path.join(out_label_dir, base_name + ".txt")

        # Write the YOLO label file
        if len(bboxes) > 0:
            write_yolo_label(bboxes, w, h, label_path)
        else:
            # If no boxes found, create an empty label file
            open(label_path, 'w').close()

        cnt += 1
    print("Processed:", cnt, "annotation files")

process_annotation_files(train_ann_paths, TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR)
process_annotation_files(val_ann_paths, VAL_IMAGES_DIR, VAL_LABELS_DIR)

neg_sample = all_negative_paths[:50]  # or however many
for img_path in tqdm(neg_sample, desc="Copying negative images"):
    filename = os.path.basename(img_path)
    # Randomly decide train or val
    if random.random() < 0.8:
        dst_img = os.path.join(TRAIN_IMAGES_DIR, filename)
        dst_label = os.path.join(TRAIN_LABELS_DIR, os.path.splitext(filename)[0] + ".txt")
    else:
        dst_img = os.path.join(VAL_IMAGES_DIR, filename)
        dst_label = os.path.join(VAL_LABELS_DIR, os.path.splitext(filename)[0] + ".txt")

    shutil.copyfile(img_path, dst_img)
    # Create empty label
    open(dst_label, 'w').close()

data_yaml = f"""
train: {TRAIN_IMAGES_DIR}
val: {VAL_IMAGES_DIR}

# single class (wake)
names:
  0: wake
"""
with open(os.path.join(WORK_DIR, "data.yaml"), 'w') as f:
    f.write(data_yaml)

print(data_yaml)

model = YOLO('yolov8x.yaml')
# or you can load a pretrained checkpoint:
# model = YOLO('yolov8n.pt')

results = model.train(
    data=os.path.join(WORK_DIR, "data.yaml"),
    imgsz=768,         # match your image size
    epochs=50,         # can adjust
    batch=42,           # adjust per GPU memory
    name="shipwake_phase1",
    project=WORK_DIR
)

# load the best model
best_model_path = os.path.join(WORK_DIR, "shipwake_phase1/weights/best.pt")
trained_model = YOLO(best_model_path)

# Let's pick random images from the validation set:
test_imgs = [os.path.join(VAL_IMAGES_DIR, f)
             for f in os.listdir(VAL_IMAGES_DIR)
             if f.lower().endswith(('.jpg', '.png'))]

random_test = random.sample(test_imgs, 5)
for img_path in random_test:
    results = trained_model.predict(source=img_path, conf=0.25, save=True, project=WORK_DIR, name="inference")
    # results are saved in WORK_DIR/inference

